{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a Python library for information examination and control. It is one of the most well known libraries for information science and AI, and is utilized by information researchers and investigators from one side of the planet to the other.\n",
    "\n",
    "Pandas gives various elements that make it ideal for information science, including:\n",
    "\n",
    ">> DataFrames: DataFrames are the center information structure in Pandas. They are two-layered tables that can store various information types, including numerics, strings, and clear cut information. DataFrames are extremely productive for information examination and control.\n",
    "\n",
    ">> Information cleaning and preprocessing: Pandas gives different instruments to information cleaning and preprocessing, for example, eliminating missing qualities, taking care of exceptions, and encoding clear cut information. These undertakings are fundamental for getting ready information for AI models.\n",
    "\n",
    ">> Highlight designing: Pandas can be utilized to make new elements from existing information. This interaction is known as element designing, and it very well may be utilized to work on the presentation of AI models.\n",
    "\n",
    ">> Information representation: Pandas additionally gives devices to information perception, for example, histograms, line plots, and disperse plots. Information perception is significant for understanding and deciphering information, and it can likewise be utilized to distinguish examples and patterns that might be hard to find in crude information.\n",
    "\n",
    ">> Not with standing these general elements, Pandas likewise gives various explicit highlights that are helpful for AI,\n",
    " for example,\n",
    ">> Cross-approval: Pandas can be utilized to execute cross-approval, which is a method for assessing the exhibition of AI models on concealed information.\n",
    "\n",
    "> Model assessment: Pandas can be utilized to work out different measurements for assessing the exhibition of AI models, like exactness, accuracy, review, and F1 score.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames look like two-layered tables or bookkeeping sheets with marked tomahawks for the two lines and segments. These designs offer hearty capacities for information assessment and change, turning into a staple in the domains of information science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from a list of lists\n",
    "data = [['nouraiz', 185], ['shaheer', 198], ['babar', 239]]\n",
    "df = pd.DataFrame(data, columns=['Name', 'Reg No'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames can likewise be made from word references, NumPy clusters, and different information sources.\n",
    "\n",
    "When a DataFrame is made, it very well may be controlled in various ways. For instance, you can:\n",
    "\n",
    "1. Select explicit lines and sections from the DataFrame\n",
    "Perform estimations on the information in the DataFrame\n",
    "Add, eliminate, and alter sections in the DataFrame\n",
    "Sort and gathering the information in the DataFrame\n",
    "Consolidation and combine different DataFrames\n",
    "DataFrames are additionally exceptionally productive for information representation. You can utilize Pandas to make different diagrams and plots from your information, for example, histograms, line plots, and dissipate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows of the DataFrame\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"name\" column from the DataFrame\n",
    "df[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average age of the people in the DataFrame\n",
    "df[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between the oldest and youngest person in the DataFrame\n",
    "df[\"age\"].max() - df[\"age\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read this CSV dataset into a Pandas DataFrame using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV dataset into a DataFrame\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average age of the people in the DataFrame\n",
    "df[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram of the ages in the DataFrame\n",
    "plt.hist(df[\"Age\"])\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of people\")\n",
    "plt.title(\"Age distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only include people who are over 30 years old\n",
    "df_filtered = df[df[\"Age\"] > 30]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some additional tips for working with Pandas DataFrames and CSV files:\n",
    "\n",
    "Use the read_csv() function to read a CSV file into a DataFrame.\n",
    "Use the to_csv() function to export a DataFrame to a CSV file.\n",
    "Use the head() and tail() functions to view the first and last few rows of a DataFrame.\n",
    "Use the info() function to get information about a DataFrame, such as the number of rows and columns, the data types, and the memory usage.\n",
    "Use the describe() function to get summary statistics for a DataFrame, such as the mean, median, standard deviation, and minimum and maximum values.\n",
    "Use the query() function to filter a DataFrame based on a Boolean expression.\n",
    "Use the sort_values() function to sort the rows in a DataFrame by one or more columns.\n",
    "Use the drop() function to remove rows and columns from a DataFrame.\n",
    "Use the rename() function to rename columns in a DataFrame.\n",
    "Use the merge() function to join two or more DataFrames togethe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning and preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a strong Python library for information control and examination. It gives a great many devices for information cleaning and preprocessing, which are vital stages in getting ready information for AI models. Here is a breakdown of a few normal information cleaning and preprocessing undertakings utilizing Pandas:\n",
    "\n",
    "Taking care of Missing Qualities:\n",
    "Missing qualities, frequently addressed as NaN (Not a Number) or invalid, can essentially influence the presentation and precision of AI models. Pandas gives capabilities to distinguish and deal with missing qualities:\n",
    "\n",
    "isnull() and notnull(): These capabilities check for missing qualities in a DataFrame or Series.\n",
    "\n",
    "dropna(): This capability eliminates lines or sections containing missing qualities in light of determined measures.\n",
    "\n",
    "fillna(): This capability replaces missing qualities with determined values, like the mean, middle, or a consistent worth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Age': [25, 30, None, 40], 'Salary': [50000, None, 60000, 70000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "missing_values = df.isnull()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('titanic.csv')\n",
    "missing_values = df.isnull()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('employees.csv')\n",
    "missing_values = df.isnull()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# making data frame from csv file\n",
    "data = pd.read_csv(\"employees.csv\")\n",
    "\n",
    "# creating bool series False for NaN values\n",
    "bool_series = pd.notnull(data[\"Gender\"])\n",
    "\n",
    "# displayed data only with team = NaN\n",
    "data[bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('employees.csv')\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('employees.csv')\n",
    "notmissing_values = df.notnull().sum()\n",
    "notmissing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropna(): This function removes rows or columns containing missing values based on specified criteria.\n",
    "dropna(): This function removes rows or columns containing missing values based on specified criteria.\n",
    "\n",
    "axis='index' removes rows with missing values.\n",
    "\n",
    "axis='columns' removes columns with missing values.\n",
    "\n",
    "how='any' removes a row or column if any value is missing.\n",
    "\n",
    "how='all' removes a row or column only if all values are missing.\n",
    "\n",
    "thresh=n removes a row or column if it has less than n non-missing values.\n",
    "\n",
    "subset=[list of columns] restricts the check for missing values to specific columns.\n",
    "\n",
    "axis='index': Drops rows that contain missing values. This is the default behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "print(\"======= before  =========\")\n",
    "print(df.shape) \n",
    "print(df.isnull().sum()) \n",
    "\n",
    "# Drop rows with any missing values\n",
    "df.dropna(axis='index', inplace=True)\n",
    "print(\"======= After  =========\")\n",
    "# Check if there are still missing values \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('employees.csv')\n",
    "# Print original DataFrame shape\n",
    "\n",
    "print(\"======= before  =========\")\n",
    "print(df.shape) \n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"======= After  =========\")\n",
    "# Drop columns with any missing values\n",
    "df.dropna(axis='columns', inplace=True)\n",
    "# Print new DataFrame shape  \n",
    "print(df.shape)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "print(\"======= BEFORE ========\")\n",
    "print(df.shape)\n",
    "print(df.isnull().sum()) \n",
    "\n",
    "# Drop columns with any missing values\n",
    "df.dropna(axis='columns', how='any', inplace=True)\n",
    "\n",
    "print(\"\\n======= AFTER ========\")\n",
    "print(df.shape) \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('employees.csv')\n",
    "print(\"======= BEFORE =======\")\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n======= AFTER =======\")\n",
    "\n",
    "df.dropna(axis='columns', how='all', inplace=True) \n",
    "\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "print(\"======= BEFORE =======\")  \n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop columns with less than 3 non-NaN values\n",
    "df.dropna(axis='columns', thresh=100, inplace=True)\n",
    "\n",
    "print(\"\\n======= AFTER =======\")\n",
    "print(df.shape) \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "print(\"======= BEFORE =======\")\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Only drop rows with missing values in columns B and C \n",
    "df.dropna(axis='index', subset=['First Name','Gender'], inplace=True)\n",
    "\n",
    "print(\"\\n======= AFTER =======\")\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "print(\"======= BEFORE =======\")\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Interpolate missing values  \n",
    "df = df['Salary'].interpolate()\n",
    "\n",
    "print(\"\\n======= AFTER =======\")\n",
    "print(df.shape)  \n",
    "print(df.isnull().sum())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying and Handling Outliers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomalies are outrageous qualities that go astray fundamentally from the other information. They can slant the aftereffects of AI models. Pandas offers strategies to identify and address exceptions:\n",
    "\n",
    "depict(): This capability gives outline measurements, including quartiles, which can assist with distinguishing expected exceptions.\n",
    "\n",
    "boxplot(): Boxplots outwardly address the dispersion of information and feature exceptions.\n",
    "\n",
    "zscore(): This capability computes the z-score, a proportion of how far a worth is from the mean. Enormous z-scores might show anomalies.\n",
    "\n",
    "Exceptions can be taken care of by eliminating them, crediting them with less outrageous qualities, or utilizing vigorous models less delicate to anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "print(df.describe()) \n",
    "\n",
    "# Create boxplots \n",
    "df.boxplot(column=['Salary', 'Bonus %'])\n",
    "\n",
    "# Calculate z-scores\n",
    "z = np.abs(stats.zscore(df))\n",
    "\n",
    "# Filter outlier rows by z-score threshold\n",
    "df = df[(z < 3).all(axis=1)]  \n",
    "\n",
    "print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
